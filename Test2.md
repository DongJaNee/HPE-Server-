# AI and Energy
- AI workload를 사용할 때 전력 소모량이 많이 발생한다.
- 전력난에 대비하기 위해 DataCenter 옆 소규모 발전소를 두고있다.
- HPE의 냉각 방향성 : 보냉식 -> 수냉식
  **이점**
  1) 1.8% more performance with DLC
  2) 19.2% more performance with K/W DLC
  3) 70% Server gead goes to water(DLC)
  4) 30% server geat goes to air (fans) 

# Liquid Cooling : A Necessity for AI
| 항목              |  **Air Cooling **    |  **Liquid Cooling **      |
| --------------- | ---------------------------- | -------------------------------- |
| **열 밀도**        | 20\~30kW/rack              | 100\~150kW/rack 이상               |
| **장점**          | - 구축 비용 낮음<br>- 기존 시설과 호환 쉬움 | - 고성능 GPU에 최적<br>- 전력 및 공간 효율 우수 |
| **단점**          | - 냉각 한계<br>- 팬 소음과 높은 PUE    | - 초기 설치비용 높음<br>- 운영 복잡도 증가      |
| **AI 워크로드 적합성** | 중소 규모 AI<br>(일반 서버/ML 실험용)   | 초대형 AI<br>(LLM 학습, HPC, GB200 등) |

---

# 대규모 AI 학습 인프라의 진화된 운영을 위한 NVIDIA Mission COntroll
- AI Factories Power the Next Industrial Revolution
- 
